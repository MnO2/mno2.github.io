<!doctype html>
<html>
    <head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-140890995-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-140890995-1');
  </script>
  <meta charset="utf-8">
  <title>Paul Meng's Blog</title>
  <link rel="canonical" href="https://blog.paulme.ng" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="AhCspkSlkxfv5A28XyOOTijnA59_q-V8rJzKakb4CFA" />

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">

  <meta property="og:title" content="Paul Meng's Blog" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://blog.paulme.ng" />

  <link href="https://fonts.googleapis.com/css?family=EB+Garamond|Roboto&display=swap" rel="stylesheet"> 
  <link href="https://fonts.googleapis.com/css?family=Noto+Sans+JP|Noto+Sans+TC&display=optional" rel="stylesheet"> 
  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/pure-min.css" integrity="sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47" crossorigin="anonymous">
  <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/grids-responsive-min.css">
  <link rel="stylesheet" href="../stylesheets/customize-1622403341.css">
  <style>
    html, button, input, select, textarea,
    .pure-g [class *= "pure-u"] {
      font-family: 'Roboto', 'Noto Sans TC', 'Noto Sans JP', sans-serif;
    }

    .post-title {
      font-family: 'EB Garamond', 'Noto Sans TC', 'Noto Sans JP', serif;
    }
  </style>
</head>

    <body>
        <div class="pure-menu pure-menu-horizontal">
            <ul class="pure-menu-list">
                <li class="pure-menu-item"><a href="../about" class="pure-menu-link">About</a></li>
                <li class="pure-menu-item"><a href="../archive.html" class="pure-menu-link">Archive</a></li>
                <li class="pure-menu-item"><a href="../rss/feed.xml" class="pure-menu-link">Subscribe</a></li>
            </ul>
        </div>
        <main class="content" role="main">
            
                <article class="post">
                    <div class="pure-g">
  <div class="pure-u-md-1-5"></div>
  <div class="pure-u-1 pure-u-md-3-5">
    <h1 class="post-title is-center"><a href="../posts/2019-07-14-cedarwood%3A-efficiently-updatable-double-array-trie-in-rust.html">cedarwood: Efficiently-Updatable Double Array Trie in Rust</a></h1>
    <div class="post-meta"><time datetime="2019-07-14 18:26">2019-07-14 18:26</time> </span>
    <div class="slot-content">
      <article>
        <p><a href="https://github.com/MnO2/cedarwood">Cedarwood</a> is an effort to <a href="https://blog.paulme.ng/posts/2019-06-30-optimizing-jieba-rs-to-be-33percents-faster-than-cppjieba.html">speed up jieba-rs</a>, an efficient implementation of trie is needed in order to satisfying the following needs.</p>
<ul>
<li>To be able to list the prefixes that exist in the dictionary with a given string. For example, given the dictionary to be <code>["a", "ab", "abc", "z", "xz", "xy"]</code> and the input string <code>abcdefg</code>. We should be able to efficiently list the prefixes <code>["a", "ab", "abc"]</code> that exist in the dictionary.</li>
<li>Due to the support of dictionary provided dynamically from the user, we need to support dynamic insertion into the data structure and at the same time still get us efficient common prefixes operation.</li>
<li>To be able to efficiently tell if the given string is in the dictionary or not.</li>
</ul>
<p>As mentioned <a href="https://blog.paulme.ng/posts/2019-06-30-optimizing-jieba-rs-to-be-33percents-faster-than-cppjieba.html">previously</a> that aho-corasick performs quite slow from my brief testing, I didn’t spend extra time to dig out why and I just accepted it. My focus was turned to refine the double array trie implementation, where at the time was <a href="https://github.com/andelf/rust-darts">rust-darts</a>. It performs quite well on the reading operations but due to its implementation was based on the <a href="http://chasen.org/~taku/software/darts/">darts</a>, a C++ implementation of static double array trie. It failed the requirement 2 mentioned above. Either we have to drop the API and getting farther away from the original python’s implementation of Jieba, or we have to find alternatives to support dynamic insertion. I did contribute to the <code>rust-darts</code> with <a href="https://github.com/andelf/rust-darts/pull/25">dynamic insertion</a>, it resolves the feature lacking issue but the speed is still quite slow. It would make the loading time and testing time for jieba to be slow as well. Then I implemented the techniques mentioned <a href="https://linux.thai.net/~thep/datrie/#Alloc">here</a> to make the trie building time much faster (from 30+ seconds down to around 5 seconds on my machine). It is much much better but I still think if we can do any better. To be fair to the <code>darts</code> implementation, the vanilla double array trie was invented by Aoe in the 1989 paper: <a href="https://ieeexplore.ieee.org/document/17222">An efficient digital search algorithm by using a double-array structure</a> with mostly read operation in mind. It did support the update operations but it also said the update speed is quite slow. There are a few techniques to speed the update operations up and I already implemented <a href="https://linux.thai.net/~thep/datrie/#Alloc">one of them</a> for the clean build.</p>
<h2 id="look-for-better-solutions">Look for better solutions</h2>
<p>I googled around to see if there are any better solution, then I found <a href="https://en.wikipedia.org/wiki/HAT-trie">HAT Trie</a>, which seems to be the state of the art implementation of the trie, with the cache in consideration. It is based on the paper published by Askitis Nikolas and Sinha Ranjan: <code>HAT-trie: A Cache-conscious Trie-based Data Structure for Strings.</code>. And it is good that <a href="https://github.com/Tessil">Tessil</a> already had <a href="https://github.com/Tessil/hat-trie">C++ implementation</a> on github with <a href="https://github.com/Tessil/hat-trie/blob/master/README.md">very detailed benchmark comparisons</a>. However, when I looked at the interface provided it seems like it only supports finding the longest prefix, and iterating through the string predictions in the dictionary matching a given prefix. It doesn’t provide the interface for the requirement 1. I looked into the <a href="https://github.com/Tessil/hat-trie/blob/master/include/tsl/htrie_hash.h#L1574">code</a> and it seems that it could potentially exposed from the implementation to support that, just that I am not familiar enough of the algorithm to do that. The concept of HAT-trie is also based on hash table with the concept of “burst” is unfamiliar to me, and since it is stored in unordered, my hunch stopped me from investing my time further to read the not-so-simple algorithm. Though the hindsight now is that the operation I need is not based on the requirement of the order in keys but the traversal of the trie, which should be supported by the longest prefix operation, just need to change the implementation. I would do that if I have more time.</p>
<h2 id="cedar-and-cedarwood">Cedar and Cedarwood</h2>
<p>The main character in this post is actually one of the candidates listed in the benchmark provided by Tessil. An double array trie implementation named <a href="http://www.tkl.iis.u-tokyo.ac.jp/~ynaga/cedar/">cedar</a> caught my eyes, since its update seems to be very efficient, it is comparable with the other fast implementations in the list. And it’s read access speed is also on the same ballpark with HAT-trie in the Dr. Askitis dataset, where the median key length is shorter than what is in the wikipedia title dataset. It definitely worths a closer look to me. The read access speed seems to be slower than HAT-trie in the long key length cases but for the Chinese segmentation scenario, the shorter key seems to be the case. We are not working on a query completion use case anyway. The author of cedar is <a href="http://www.tkl.iis.u-tokyo.ac.jp/~ynaga/">Naoki Yoshinaga</a>. He pointed us to the paper of <code>A Self-adaptive Classifier for Efficient Text-stream Processing</code> for further reading on his webpage but it is mostly an NLP paper but not a data structure paper, it only has one or two paragraphs describing the working on his improvement on double array trie. In the paper he cited another one, but you couldn’t find the paper on any English website, even scihub. It turned out it is a paper in Japanese and I found the pdf on the Japanese website with the title of <code>タブル配列による動的辞書の構成と評価</code>. Even though I can understand basic to intermediate Japanese, it still didn’t address that much into the detail in that Japanese paper. Therefore I decided to read the code directly.</p>
<p>It is a header-only C++ implementation and the code is very much shortened to reduce the header size, it is generally ok to read with a C++ formatter from IDE or VSCode, but it also took me a while to get the core concept behind it on improvement techniques due to the lack of comments. And with the <code>cedarwood</code> rust porting implementation, I added much more comments so it should be much easier to understand how it is working, but it is a required reading to read the original double array trie paper so that at least you know how the <code>base</code> and <code>check</code> works in double array trie cases. The following I’ll briefly talk about the concept behind the skills.</p>
<h2 id="the-key-concepts-in-the-algorithm">The Key Concepts in the Algorithm</h2>
<p>The inefficiency in the update operation of the vanilla double array trie is caused by the free slot searching. The original paper simply implies that you could use brute-force approach to iterate through the index in <code>check</code> and see if they are marked as owned, and iterate through until the location where you have the free slots distribution exactly match what you want (suppose you are relocating an existing trie node to a new free location). The technique specified <a href="https://linux.thai.net/~thep/datrie/#Alloc">here</a> is basically leveraging on the value space on each block, and you can use negative integer to specify the free slot location and make them into an array-index based doubly linked-list, and you could make the brute forte iteration down to a fast-skipping linked list traversal. However, that technique doesn’t address the case where you still need to iterate your char set (2^21 in the unicode scalar case, or 2^8 if you are working on UTF-8) to check every slot and make sure the slots distributions match your need. The technique used in cedar is basically to address this problem, by maintain the bookkeeping of two kind of information: <code>NInfo</code> and <code>Block</code></p>
<pre><code>struct NInfo {
    sibling: u8, // the index of right sibling, it is 0 if it doesn't have a sibling.
    child: u8,   // the index of the first child
}</code></pre>
<pre><code>struct Block {
    prev: i32,   // previous block's index, 3 bytes width
    next: i32,   // next block's index, 3 bytes width
    num: i16,    // the number of slots that is free, the range is 0-256
    reject: i16, // a heuristic number to make the search for free space faster, it is the minimum number of iteration in each trie node it has to try before we can conclude that we can reject this block. If the number of kids for the block we are looking for is less than this number then this block is worthy of searching.
    trial: i32,  // the number of times this block has been probed by `find_places` for the free block.
    e_head: i32, // the index of the first empty elemenet in this block
}</code></pre>
<p>The <code>NInfo</code> is probably standing for “Trie Node Information”, it maintains the trie parent-children and siblings information, since these are the information needed when relocating the trie node around. You have to know which node has smaller size in its children, you could just traverse down and counting the number of children one by one. And you could iterate through the sibling chain when you really need to do the move and compare if the slots fit the potential free spaces.</p>
<p>As for <code>Block</code>, it maintains the book-keeping of the free space selection, simulating how you look at it of the each block (256 in size) when you squint at the data structure. It book keeps the information like how many free slots this block still have so that you could quickly prune the branch if the number of the free slots is less than the number of children the trie node you are relocating. Further more, the algorithm categorize the blocks into three kinds</p>
<ul>
<li>Full: The block where all of the slots are taken</li>
<li>Closed: The block where all of the slots are taken except for one</li>
<li>Open: The rest, but most of the time it is the free slots that just allocated at the end of the <code>base</code> and <code>check</code> when you resize the array.</li>
</ul>
<p>Each of them is put in the doubly-linked-list of their own kind. During the search process, you only need to look for the free space from <code>Closed</code> type block if you are inserting a single-child node, since it only needs one slot. You only need to look for <code>Open</code> block when you are relocating a node with more children. And since it is linked list all you need to do is just insert and remove the block from the linked-list, which is constant time. And insert / remove from the right kind of linked list after you update the node with inserted <code>label</code>.</p>
<h2 id="benchmarks">Benchmarks</h2>
<p>With the above algorithm mentioned, let’s take a look of <code>cedarwood</code>’s benchmark, the rust implementation of <code>cedar</code>. My laptop’s spec is as follows:</p>
<pre><code>MacBook Pro (13-inch, 2017, Two Thunderbolt 3 ports)
2.5 GHz Intel Core i7
16 GB 2133 MHz LPDDR3</code></pre>
<p>And here is the benchmark against C++ version and <code>rust-darts</code></p>
<h3 id="build">Build</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">impl</th>
<th style="text-align: left;">time</th>
<th style="text-align: left;">version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">cedar</td>
<td style="text-align: left;">71 ms</td>
<td style="text-align: left;">2014-06-24</td>
</tr>
<tr class="even">
<td style="text-align: left;">cedarwood</td>
<td style="text-align: left;">64 ms</td>
<td style="text-align: left;">0.4.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rust-darts</td>
<td style="text-align: left;">201 ms</td>
<td style="text-align: left;">b1a6813</td>
</tr>
</tbody>
</table>
<h3 id="query">Query</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">impl</th>
<th style="text-align: left;">time</th>
<th style="text-align: left;">version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">cedar</td>
<td style="text-align: left;">10 ms</td>
<td style="text-align: left;">2014-06-24</td>
</tr>
<tr class="even">
<td style="text-align: left;">cedarwood</td>
<td style="text-align: left;">10 ms</td>
<td style="text-align: left;">0.4.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rust-darts</td>
<td style="text-align: left;">18 ms</td>
<td style="text-align: left;">b1a6813</td>
</tr>
</tbody>
</table>
<p>For the <code>rust-darts</code> it is significantly slower than both of <code>cedar</code> and <code>cedarwood</code>, and it has extra requirement on the construction of the dictionary to be that the dictionary has to be lexicographically sorted. For <code>cedar</code> building contains the time for file reading (with 65536 buffer size) so it actually even slightly faster, but the querying time contains memory-only operation. I am too lazy to change the benchmarking code since it is using no-copying techniques by moving the pointer until the next new line and it is troublesome for me to change the rust implementation to be the same way so that to compare apple to apple. The <code>cedar</code> code was compiled with <code>-O3</code> and rust’s code is compiled with <code>--release</code> and only measure the time for the operations in the memory. You can see that the build time, that is <code>update</code> are roughly the same for C++ and Rust. And in the query case the Rust version is slightly slower than C++ but basically comparable. I couldn’t find where I could further optimize the Rust version since the code for the lookup case is quite simple and not much space to optimize on the source code level without going to the <code>unsafe</code> resort. Not sure where I could tune to speed it up, please let me know if you identify the part I could do further.</p>
<h2 id="lesson-learned">Lesson Learned</h2>
<p>Rust’s implementation is as comparable as C++’s implementation without much effort, I don’t need to go with <code>unsafe</code> and keep the majority of the code compiler-checked for memory safety. There is only one place where I need to go by <code>unsafe</code> block due to linked-list update but not due to the performance. There are a few handy features in C++ that I would miss, like const generics to make the data structure parameterized on the type level, but overall it is not a big issue in the cedar case. Or template specialization where you could leverage on different implementations based on the type you specify. Since <code>cedarwood</code> only save the word id in normal mode. It might require that for the support of reduced-trie feature where the value is stored in place, but right now <code>cedarwood</code> only has limited support on that so it is no big issue. Overall it is a smooth experience on porting.</p>

      </article>
    </div>
  </div>
  <div class="pure-u-md-1-5"></div>
</div>

                </article>
            
                <article class="post">
                    <div class="pure-g">
  <div class="pure-u-md-1-5"></div>
  <div class="pure-u-1 pure-u-md-3-5">
    <h1 class="post-title is-center"><a href="../posts/2019-07-01-%E6%9C%80%E4%BD%B3%E5%8C%96jieba-rs%E4%B8%AD%E6%96%87%E6%96%B7%E8%A9%9E%E6%80%A7%E8%83%BD%E6%B8%AC%E8%A9%A6%28%E5%BF%AB%E4%BA%8Ecppjieba-33%25%29.html">最佳化 jieba-rs 中文斷詞性能測試 (快于 cppjieba 33%)</a></h1>
    <div class="post-meta"><time datetime="2019-07-01 15:36">2019-07-01 15:36</time> </span>
    <div class="slot-content">
      <article>
        <p>昨晚寫了一篇關於最佳化 <a href="https://github.com/messense/jieba-rs">jieba-rs</a> 英文的<a href="https://blog.paulme.ng/posts/2019-06-30-optimizing-jieba-rs-to-be-33percents-faster-than-cppjieba.html">介紹</a>，但想說 jieba 的使用者多半還是在中文圈，對於宣傳來講 hacker news 跟 reddit 可能無法觸及到真正會使用的使用者，於是為了宣傳，也是為了讓 search engine 可以搜尋到，就來把性能的部分另外寫成中文的一篇。關於過程我就不再重新用中文再寫一次了，實在太累人了。有興趣的人可以閱讀<a href="https://blog.paulme.ng/posts/2019-06-30-optimizing-jieba-rs-to-be-33percents-faster-than-cppjieba.html">英文版</a></p>
<p>測試機器的機器規格如下</p>
<pre><code>MacBook Pro (13-inch, 2017, Two Thunderbolt 3 ports)
2.5 GHz Intel Core i7
16 GB 2133 MHz LPDDR3</code></pre>
<p>測試過程仿照<a href="http://yanyiwu.com/work/2015/06/14/jieba-series-performance-test.html">結巴(Jieba)中文分詞系列性能評測</a>所描述，先一行一行讀取檔案圍城到一個陣列裡，然後循環 50 次對圍城每行文字作為一個句子進行斷詞。 分詞算法都是採用精確模式，也就是包含了 HMM 的部分。</p>
<p>耗時的資料如下，從高到低排序</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">實作</th>
<th style="text-align: center;">耗時</th>
<th style="text-align: center;">版本 .</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">cppjieba</td>
<td style="text-align: center;">6.219s</td>
<td style="text-align: center;">866d0e8</td>
</tr>
<tr class="even">
<td style="text-align: left;">jieba-rs (master)</td>
<td style="text-align: center;">4.330s</td>
<td style="text-align: center;">a198e44</td>
</tr>
<tr class="odd">
<td style="text-align: left;">jieba-rs (darts)</td>
<td style="text-align: center;">4.138s</td>
<td style="text-align: center;">ab2fbfe</td>
</tr>
</tbody>
</table>
<p>以上耗時都是計算斷詞過程的耗時，不包括字典載入的耗時。</p>
<p>這篇會著重於評測只是為了宣傳，並不想陷入語言之爭，這也是我英文版有寫主要是分享關於用 Rust 最佳化的經驗，也是為了我自己衡量可以在工作中多認真使用 Rust 為目的。</p>

      </article>
    </div>
  </div>
  <div class="pure-u-md-1-5"></div>
</div>

                </article>
            
        </main>

        <div class="pure-g">
          <div class="pure-u-md-1-5"></div>
          <div class="pure-u-md-3-5">
          <nav class="main-nav">
            
            <span class="newer-posts">
              <a href="../11/">&larr; Newer Posts</a>
            </span>
            
            
            <span class="older-posts" style="float:right">
              <a href="../13/">Older Posts &rarr;</a>
            </span>
            
          </nav>
          </div>
          <div class="pure-u-md-1-5"></div>
        </div>

        <div class="pure-g">
          <div class="pure-u-md-1-5"></div>
          <div class="pure-u-1 pure-u-md-3-5">
            <div class="page-number is-center">Page 12 of 59</div>
            <footer class="site-footer">
              <div class="inner is-center">
                <section class="copyright">All contents are copyrighted by Paul Meng, CC BY-NC-SA © 2019</section>
              </div>
            </footer>
          </div>
          <div class="pure-u-md-1-5"></div>
        </div>
    </body>
</html>
